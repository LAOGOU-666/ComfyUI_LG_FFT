import torch
import torchvision.transforms.v2 as T
import numpy as np
import cv2

def tensor_to_image(image):
    return np.array(T.ToPILImage()(image.permute(2, 0, 1)).convert('RGB'))

def image_to_tensor(image):
    return T.ToTensor()(image).permute(1, 2, 0)

class LG_FFTNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image": ("IMAGE", ),
            }
        }

    RETURN_TYPES = ("IMAGE", "FFTData")
    RETURN_NAMES = ("image", "FFTData")
    FUNCTION = "toFFT"
    CATEGORY = "ğŸˆLAOGOU"

    def toFFT(self, image):
        FFTImageList = []
        FFT_Channel_Data = []
        channelCount = 3
        imageCount = image.shape[0]

        for i in range(image.shape[0]):
            sourceImg = image[i]
            cv2Image = (sourceImg.contiguous() * 255).byte()

            dim = sourceImg.dim()
            if dim == 3:
                R_channel = cv2Image[:, :, 0]
                G_channel = cv2Image[:, :, 1]
                B_channel = cv2Image[:, :, 2]

                fshiftData = []
                # å‚…é‡Œå¶å˜æ¢
                R_fft = np.fft.fft2(R_channel)
                R_fshift = np.fft.fftshift(R_fft)
                fshiftData.append(R_fshift)
                G_fft = np.fft.fft2(G_channel)
                G_fshift = np.fft.fftshift(G_fft)
                fshiftData.append(G_fshift)
                B_fft = np.fft.fft2(B_channel)
                B_fshift = np.fft.fftshift(B_fft)
                fshiftData.append(B_fshift)

                R_img = np.log(np.abs(R_fshift))
                G_img = np.log(np.abs(G_fshift))
                B_img = np.log(np.abs(B_fshift))

                R_img = R_img / np.max(R_img)
                G_img = G_img / np.max(G_img)
                B_img = B_img / np.max(B_img)

                fftImg = np.dstack((R_img, G_img, B_img)).astype(np.float32)
                FFT_Channel_Data.append(fshiftData)
                FFTImageList.append(fftImg)
            else:
                channelCount = 1
                fshiftData = []
                # å•é€šé“å›¾åƒå‚…é‡Œå¶å˜æ¢
                R_fft = np.fft.fft2(cv2Image)
                R_fshift = np.fft.fftshift(R_fft)
                fshiftData.append(R_fshift)
                fftImg = np.log(np.abs(R_fshift))
                fftImg = fftImg / np.max(fftImg)
                fftImg = fftImg.astype(np.float32)
                FFTImageList.append(fftImg)
                FFT_Channel_Data.append(fshiftData)

        tensors_out = torch.stack([torch.from_numpy(np_array) for np_array in FFTImageList])
        FFT_Data = {'channelCount': channelCount, 'FFT_Channel_Data': FFT_Channel_Data, 'imageCount': imageCount}

        return (tensors_out, FFT_Data)


def low_pass_filter(shape, cutoff):
    """ç”Ÿæˆä½é€šæ»¤æ³¢å™¨ï¼Œä¿ç•™ä½äº cutoff çš„é¢‘ç‡"""
    rows, cols = shape
    center_row, center_col = rows // 2, cols // 2
    r, c = np.ogrid[:rows, :cols]
    distance = np.sqrt((r - center_row) ** 2 + (c - center_col) ** 2)
    mask = (distance <= cutoff).astype(np.float32)
    return mask

def high_pass_filter(shape, cutoff):
    """ç”Ÿæˆé«˜é€šæ»¤æ³¢å™¨ï¼Œä¿ç•™é«˜äº cutoff çš„é¢‘ç‡"""
    rows, cols = shape
    center_row, center_col = rows // 2, cols // 2
    r, c = np.ogrid[:rows, :cols]
    distance = np.sqrt((r - center_row) ** 2 + (c - center_col) ** 2)
    mask = (distance >= cutoff).astype(np.float32)
    return mask

def band_pass_filter(shape, low_cutoff, high_cutoff):
    """ç”Ÿæˆå¸¦é€šæ»¤æ³¢å™¨ï¼Œä¿ç•™ low_cutoff åˆ° high_cutoff ä¹‹é—´çš„é¢‘ç‡"""
    rows, cols = shape
    center_row, center_col = rows // 2, cols // 2
    r, c = np.ogrid[:rows, :cols]
    distance = np.sqrt((r - center_row) ** 2 + (c - center_col) ** 2)
    mask = np.logical_and(distance >= low_cutoff, distance <= high_cutoff).astype(np.float32)
    return mask
# åº”ç”¨è¾“å…¥çš„è‡ªå®šä¹‰é®ç½©åˆ°å‚…é‡Œå¶é¢‘è°±ä¸Š
def ApplyMask(l_fshift, l_mask, filter_type="low_pass", low_cutoff=10, high_cutoff=50):
    # å°† l_fshift è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œç¡®ä¿å…¼å®¹æ€§
    if isinstance(l_fshift, torch.Tensor):
        l_fshift = l_fshift.cpu().numpy()
    
    # å°† mask ä¹Ÿè½¬æ¢ä¸º numpy æ•°ç»„
    if isinstance(l_mask, torch.Tensor):
        l_mask = l_mask.cpu().numpy()

    rows, cols = l_fshift.shape

    # æ ¹æ®æ»¤æ³¢å™¨ç±»å‹é€‰æ‹©å¯¹åº”çš„æ»¤æ³¢å™¨
    if filter_type == "low_pass":
        filter_mask = low_pass_filter((rows, cols), high_cutoff)
    elif filter_type == "high_pass":
        filter_mask = high_pass_filter((rows, cols), low_cutoff)
    elif filter_type == "band_pass":
        filter_mask = band_pass_filter((rows, cols), low_cutoff, high_cutoff)

    # ç»“åˆè¾“å…¥çš„é®ç½©ï¼Œæ»¤æ³¢å™¨åªä½œç”¨äºæŒ‡å®šåŒºåŸŸ
    combined_mask = l_mask * filter_mask

    # åº”ç”¨æ»¤æ³¢å™¨ï¼Œç¡®ä¿é¢‘è°±å’Œé®ç½©ç±»å‹ä¸€è‡´
    f = l_fshift * combined_mask  # åœ¨é¢‘è°±ä¸Šåº”ç”¨æ»¤æ³¢å™¨ï¼Œå½¢çŠ¶ä¸å˜
    ishift = np.fft.ifftshift(f)
    iimg = np.fft.ifft2(ishift)
    iimg = np.abs(iimg)
    
    return f, iimg



class LG_IFFTNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "ff": ("FFTData", ),
                "mask": ("MASK", ),  # è¾“å…¥é®ç½©
                "filter_type": (["low_pass", "high_pass", "band_pass"], {"default": "low_pass"}),  # æ»¤æ³¢ç±»å‹
                "low_cutoff": ("INT", {"default": 10, "min": 0, "max": 1000}),
                "high_cutoff": ("INT", {"default": 50, "min": 0, "max": 1000}),
                "invert_mask": ("BOOLEAN", {"default": False})  # æ˜¯å¦åè½¬é®ç½©
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "fromFFT"
    CATEGORY = "ğŸˆLAOGOU"

    def DoOneChannel(self, fshift, mask, filter_type="low_pass", low_cutoff=10, high_cutoff=50, invert_mask=False):
        # å¦‚æœ invert_mask ä¸º Trueï¼Œåˆ™åè½¬é®ç½©ï¼Œé‡‡ç”¨ 1 - mask é€»è¾‘
        if invert_mask:
            mask = 1 - mask  # å°† 1 å˜ä¸º 0ï¼Œ0 å˜ä¸º 1
        
        # åº”ç”¨é®ç½©å’Œæ»¤æ³¢å™¨
        fshift_masked, hi_pass_img = ApplyMask(fshift, mask, filter_type, low_cutoff, high_cutoff)
        return hi_pass_img / 255

    def fromFFT(self, ff, mask, filter_type="low_pass", low_cutoff=10, high_cutoff=50, invert_mask=False):
        channel_count = ff['channelCount']
        image_count = ff['imageCount']
        res = []

        for i in range(image_count):
            if channel_count == 3:
                # åˆ†åˆ«å¤„ç† Rã€Gã€B é€šé“
                f0 = ff['FFT_Channel_Data'][i][0]
                f1 = ff['FFT_Channel_Data'][i][1]
                f2 = ff['FFT_Channel_Data'][i][2]

                # å¯¹æ¯ä¸ªé€šé“åº”ç”¨é®ç½©å’Œæ»¤æ³¢å™¨ï¼Œä¼ é€’ invert_mask å‚æ•°
                out0 = self.DoOneChannel(f0, mask, filter_type, low_cutoff, high_cutoff, invert_mask)
                out1 = self.DoOneChannel(f1, mask, filter_type, low_cutoff, high_cutoff, invert_mask)
                out2 = self.DoOneChannel(f2, mask, filter_type, low_cutoff, high_cutoff, invert_mask)

                # å»æ‰å¤šä½™çš„ç»´åº¦ï¼Œä½¿å…¶å˜ä¸º (931, 421)
                out0 = np.squeeze(out0)
                out1 = np.squeeze(out1)
                out2 = np.squeeze(out2)

                # åˆå¹¶é€šé“å¹¶ç¡®ä¿å½¢çŠ¶ä¸º (931, 421, 3)
                done_img = np.dstack((out0, out1, out2)).astype(np.float32)

                # æ·»åŠ  batch ç»´åº¦ï¼Œç¡®ä¿å…¶ä¸º (1, 931, 421, 3)
                done_img = np.expand_dims(done_img, axis=0)

                # æ·»åŠ ç»“æœåˆ° res åˆ—è¡¨ä¸­
                res.append(done_img)
            else:
                # å•é€šé“å›¾åƒå¤„ç†
                f0 = ff['FFT_Channel_Data'][i]
                done_img = self.DoOneChannel(f0, mask, filter_type, low_cutoff, high_cutoff, invert_mask)

                # å»æ‰å¤šä½™çš„ç»´åº¦ï¼Œä½¿å…¶å˜ä¸º (931, 421)
                done_img = np.squeeze(done_img.astype(np.float32))

                # å°†å•é€šé“æ‰©å±•ä¸ºä¸‰é€šé“ (å¤åˆ¶ä¸‰æ¬¡ä»¥å˜ä¸º RGB)
                done_img = np.stack([done_img] * 3, axis=-1)

                # æ·»åŠ  batch ç»´åº¦ï¼Œç¡®ä¿å…¶ä¸º (1, 931, 421, 3)
                done_img = np.expand_dims(done_img, axis=0)

                # æ·»åŠ ç»“æœåˆ° res åˆ—è¡¨ä¸­
                res.append(done_img)

        # å¦‚æœè¾“å‡ºæ˜¯å•å¼ å›¾åƒï¼Œåˆ™å †å ç»“æœå¹¶è¿”å›
        tensors_out = torch.stack([torch.from_numpy(np_array) for np_array in res])

        return tensors_out



NODE_CLASS_MAPPINGS = {
    "LG_FFTNode": LG_FFTNode,
    "LG_IFFTNode": LG_IFFTNode


}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LG_FFTNode": "ğŸˆLG_FFT",
    "LG_IFFTNode": "ğŸˆLG_IFFT"
}
